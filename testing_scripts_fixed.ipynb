{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import image_to_train as tr\n",
    "from model import get_model\n",
    "import test_func as test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model on the Urban100 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this script when preprocessing Urban100 dataset\n",
    "ds_path = os.path.join('Urban 100', 'X2 Urban100', 'X2')\n",
    "HR_path = os.path.join(ds_path, 'HIGH X2 Urban')\n",
    "LR_path = os.path.join(ds_path, 'LOW X2 Urban')\n",
    "\n",
    "files_Y = sorted([os.path.join(HR_path, filename) for filename in os.listdir(HR_path)])\n",
    "files_X = sorted([os.path.join(LR_path, filename) for filename in os.listdir(LR_path)])\n",
    "\n",
    "files_Y = tf.convert_to_tensor(files_Y, tf.string)\n",
    "files_X = tf.convert_to_tensor(files_X, tf.string)\n",
    "\n",
    "def map_func(file):\n",
    "    image = tf.io.read_file(file)\n",
    "    image = tf.image.decode_image(image, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tr.to_luminance(image)                          # remove if you are going to compare the colored images\n",
    "    return tf.squeeze(image)\n",
    "\n",
    "Y = [tf.expand_dims(map_func(im), axis=-1) for im in files_Y]\n",
    "X_sub = [tf.image.decode_image(tf.io.read_file(x), dtype=tf.float32) for x in files_X]\n",
    "X_sub = [tr.preprocess_single_image(x, channel_last=True, batch_dimension=True) for x in X_sub]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load self-trained weights\n",
    "test_model = get_model()\n",
    "test_model.load_weights(os.path.join('saved_weights', 'exp', '240'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ims = []\n",
    "ssim_scores = []\n",
    "psnr_scores = []\n",
    "\n",
    "for x in X_sub:\n",
    "    y_pred = test_model(x)\n",
    "    pred_ims.append(tf.expand_dims(tr.bands_to_image(x+y_pred), axis=-1))\n",
    "    \n",
    "for x, y in zip(pred_ims, Y):\n",
    "    ssim_scores.append(tf.image.ssim(x, y, max_val=1.0))\n",
    "    psnr_scores.append(tf.image.psnr(x, y, max_val=1.0))\n",
    "\n",
    "avg_ssim_score = sum(ssim_scores) / len(ssim_scores)\n",
    "avg_psnr_score = sum(psnr_scores) / len(psnr_scores)\n",
    "print('psnr score for trained model: {} \\nssim score for trained model: {}'.format(avg_psnr_score, avg_ssim_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing with the Base_x2 Model (Model Used in Paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights trained by the author\n",
    "x2_weight_path = os.path.join('saved_weights', 'Weightx2', 'x2.ckpt')\n",
    "model = get_model()\n",
    "x2_model = test.load_x2_from_weights(model, x2_weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ims_x2 = []\n",
    "ssim_scores_x2 = []\n",
    "psnr_scores_x2 = []\n",
    "for x in X_sub:\n",
    "    y_pred = x2_model(x)\n",
    "    pred_ims_x2.append(tf.expand_dims(tr.bands_to_image(x+y_pred), axis=-1))\n",
    "\n",
    "for x, y in zip(pred_ims_x2, Y):\n",
    "    ssim_scores_x2.append(tf.image.ssim(x, y, max_val=1.0))\n",
    "    psnr_scores_x2.append(tf.image.psnr(x, y, max_val=1.0))\n",
    "avg_ssim_score_x2 = sum(ssim_scores_x2) / len(ssim_scores_x2)\n",
    "avg_psnr_score_x2 = sum(psnr_scores_x2) / len(psnr_scores_x2)\n",
    "\n",
    "print('psnr score for trained model: {} \\nssim score for trained model: {}'.format(avg_psnr_score, avg_ssim_score))\n",
    "print('psnr score for base x2: {} \\nssim score for base x2: {}'.format(avg_psnr_score_x2, avg_ssim_score_x2))\n",
    "\n",
    "# believe that the Urban100 scores is different due to changes in the original dataset since the original paper produced higher scores for PSNR and SSIM\n",
    "# Model trained by self have lower scored since they were trained on bicubic downsampled images rather than the LR dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Model with Bicubic Downsampling on Arbitrary Datasets \n",
    "# (Not Accurate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import image_to_train as tr\n",
    "from model import get_model\n",
    "import test_func as test\n",
    "\n",
    "downsample_scale = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HR_path = os.path.join('Urban 100', 'X2 Urban100', 'X2', 'HIGH X2 Urban')\n",
    "files = [os.path.join(HR_path, filename) for filename in sorted(os.listdir(HR_path))[:20]]\n",
    "# files = ['IMG_0275 2.png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_Y = [tf.expand_dims(test.upsample(p, scale=1), axis=-1) for p in files]\n",
    "downsample_images = [test.downsample(p, downsample_scale, batch=False) for p in files]\n",
    "downsample_sub_bands = [tf.expand_dims(tr.dwt_transform(downsample_image, channel_last=True), axis=0) for downsample_image in downsample_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = get_model()\n",
    "x2_model = get_model()\n",
    "x2_weight_path = os.path.join('saved_weights', 'Weightx2', 'x2.ckpt')\n",
    "\n",
    "x2_model = test.load_x2_from_weights(x2_model, x2_weight_path)\n",
    "model_test.load_weights(os.path.join('saved_weights', 'exp', '240'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test_pred_ims = []\n",
    "x2_pred_ims = []\n",
    "\n",
    "for x in downsample_sub_bands:\n",
    "    model_test_y_pred = model_test(x)\n",
    "    model_test_pred_ims.append(tf.expand_dims(tr.bands_to_image(x+model_test_y_pred), axis=-1))\n",
    "\n",
    "    x2_y_pred = x2_model(x)\n",
    "    x2_pred_ims.append(tf.expand_dims(tr.bands_to_image(x+x2_y_pred), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_psnr_score = test.calculate_psnr(x2_pred_ims, im_Y)\n",
    "model_test_psnr_score = test.calculate_psnr(model_test_pred_ims, im_Y)\n",
    "\n",
    "x2_ssim_score = test.calculate_ssim(x2_pred_ims, im_Y)\n",
    "model_test_ssim_score = test.calculate_ssim(model_test_pred_ims, im_Y)\n",
    "\n",
    "downsample_images_channel = [tf.expand_dims(downsample_image, axis=-1) for downsample_image in downsample_images]\n",
    "baseline_score_ssim = test.calculate_ssim(downsample_images_channel, im_Y)\n",
    "baseline_score_psnr = test.calculate_psnr(downsample_images_channel, im_Y)\n",
    "\n",
    "print('psnr score for trained model: {} \\nssim score for trained model: {}'.format(\n",
    "    model_test_psnr_score, model_test_ssim_score))\n",
    "print('psnr score for x2 model: {} \\nssim score for x2 model: {}'.format(x2_psnr_score, x2_ssim_score))\n",
    "print('psnr score for bicubic: {} \\nssim score for bicubic: {}'.format(baseline_score_psnr, baseline_score_ssim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.write_images_to_path('saved_images', tf.image.encode_png())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
