{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Training DWSR Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3140674ed92229ab"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-24T07:52:30.443769Z",
     "start_time": "2024-02-24T07:52:26.874973Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-23 23:52:28.019007: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from model import get_model, get_loss, get_optimizer, get_cosine_optimizer\n",
    "from image_to_train import bands_to_image, display_image, unpack_numpy_subimages, preprocess_single_train\n",
    "import image_to_train"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1396/1396 files extracted successfully\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 60\n",
    "CLIP_NORM = 0.01\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "file_path = os.path.join('DIV2K_train_HR', 'x2_train_subimages')\n",
    "X, Y = unpack_numpy_subimages(file_path)\n",
    "print('subimage_shapes: {}, number of training subimages: {}'.format(X.shape, len(X)))\n",
    "example_x = tf.expand_dims(bands_to_image(X[0]), axis=2)\n",
    "example_y = tf.expand_dims(bands_to_image(X[0]+Y[0]), axis=2)\n",
    "print('PSNR similarity:', tf.image.psnr(example_x, example_y, max_val=1.0).numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-24T07:52:30.444743Z"
    }
   },
   "id": "56e804e714c9f5a7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_size = int(0.8*len(X))\n",
    "valid_size = int(0.15*len(X))\n",
    "\n",
    "X = np.moveaxis(X, 1, -1)\n",
    "Y = np.moveaxis(Y, 1, -1)\n",
    "\n",
    "X = tf.convert_to_tensor(X)\n",
    "Y = tf.convert_to_tensor(Y)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
    "dataset = dataset.shuffle(buffer_size=BATCH_SIZE*10) # may need to increase since the same images are next to each other\n",
    "\n",
    "train_dataset = dataset.take(train_size)\n",
    "valid_dataset = dataset.skip(train_size).take(valid_size)\n",
    "test_dataset  = dataset.skip(train_size+valid_size)\n",
    "\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "valid_dataset = valid_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset  = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-21T19:23:55.500922Z"
    }
   },
   "id": "684c717f2f6c5559",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "loss = get_loss()\n",
    "TOTAL_STEPS = EPOCHS*(train_size//BATCH_SIZE)\n",
    "optimizer = get_cosine_optimizer(initial_learning_rate=0.001, decay_steps=TOTAL_STEPS)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-21T19:23:55.490348Z"
    }
   },
   "id": "41eec9d609f742ea",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# callback = \n",
    "optimizer.iterations.numpy()\n",
    "op = get_cosine_optimizer()\n",
    "op.iterations.numpy()\n",
    "optimizer = get_cosine_optimizer()\n",
    "optimizer.iterations"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-21T19:23:55.496581Z"
    }
   },
   "id": "81094ce3f6ba83a5",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training Loop"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0a55caf12951a1c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# custom training loop\n",
    "\n",
    "valid_prog = []\n",
    "train_prog = []\n",
    "checkpoint = os.path.join('saved_weights', 'cos_800_x2')\n",
    "for epoch in range(EPOCHS):\n",
    "    total_train_loss = 0\n",
    "    train_batches = 0\n",
    "    loss_value = 0\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = model(x_batch_train, training=True)\n",
    "            loss_value = loss(y_batch_train, predictions)\n",
    "        gradients = tape.gradient(loss_value, model.trainable_variables)\n",
    "\n",
    "        # unsure if we should use norm or global norm\n",
    "        clipped_gradients, _ = tf.clip_by_global_norm(gradients, CLIP_NORM)\n",
    "        optimizer.apply_gradients(zip(clipped_gradients, model.trainable_variables))\n",
    "        \n",
    "        total_train_loss += loss_value\n",
    "        train_batches += 1\n",
    "    lr = optimizer.lr\n",
    "    print('lr: ', lr)\n",
    "        \n",
    "    # Validation loop\n",
    "    \"\"\"\n",
    "    add validation losses for PSNR and SSIM\n",
    "    \"\"\"\n",
    "    total_val_loss = 0\n",
    "    num_batches = 0\n",
    "    min_val_loss = float('inf')\n",
    "    for x_batch_val, y_batch_val in valid_dataset:\n",
    "        val_predictions = model(x_batch_val, training=False)        # unsure about training=False\n",
    "\n",
    "        val_loss = loss(y_batch_val, val_predictions)\n",
    "        total_val_loss += val_loss\n",
    "        num_batches += 1\n",
    "\n",
    "    avg_val_loss = total_val_loss / num_batches\n",
    "    avg_train_loss = total_train_loss / train_batches\n",
    "    valid_prog.append(avg_val_loss)\n",
    "    if (epoch % 5 == 0 or epoch == EPOCHS - 1) and avg_val_loss < min_val_loss:\n",
    "        min_val_loss = avg_val_loss\n",
    "        model.save_weights(checkpoint)\n",
    "        \n",
    "    print(f\"Epoch {epoch + 1}, Validation Loss: {avg_val_loss.numpy()}, Train loss: {avg_train_loss.numpy()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-21T19:23:55.499016Z"
    }
   },
   "id": "f89001a7dc216aee",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.plot(valid_prog)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T19:23:55.523364Z",
     "start_time": "2024-02-21T19:23:55.499895Z"
    }
   },
   "id": "fac950966bd5411b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39msave_weights(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msaved_weights\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcos_model100_100\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# model.save(os.path.join('saved_models', 'first_model100_100.keras'))      # doesn't work due to custom objects\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save_weights(os.path.join('saved_weights', 'cos_model100_100'))\n",
    "# model.save(os.path.join('saved_models', 'first_model100_100.keras'))      # doesn't work due to custom objects"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T23:41:40.238121Z",
     "start_time": "2024-02-21T23:41:40.186377Z"
    }
   },
   "id": "52f1a8c31a4ba1bb",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_image = tf.io.read_file(os.path.join('Testx2Color', '0958x2.png'))\n",
    "test_image = tf.io.decode_png(test_image)\n",
    "test_train = preprocess_single_train(test_image)\n",
    "init_test_x = test_train[0]\n",
    "init_test_y = test_train[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-20T21:28:44.262880Z"
    }
   },
   "id": "1946204c3ffa6fa4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# display_image(bands_to_image(init_test_x+init_test_y))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T21:28:44.264977Z",
     "start_time": "2024-02-20T21:28:44.264403Z"
    }
   },
   "id": "fc049f06278688ba",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "loaded_model = get_model()\n",
    "loaded_model.load_weights(os.path.join('saved_weights', 'first_model100_100'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-20T21:28:44.265923Z"
    }
   },
   "id": "82204ac87f4e4bde"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_x = np.moveaxis(init_test_x, 0, -1)\n",
    "test_x = tf.expand_dims(test_x, axis=0)\n",
    "\n",
    "test_out = loaded_model(test_x)\n",
    "test_out = tf.squeeze(test_out)\n",
    "test_out =np.moveaxis(test_out, -1, 0)\n",
    "display_image(test_out)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-20T21:28:44.267360Z"
    }
   },
   "id": "76a3b6436371fe95",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "display_image(init_test_y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-20T21:28:44.268708Z"
    }
   },
   "id": "ad7e6006c31063c6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# low res image\n",
    "lowres = bands_to_image(init_test_x)\n",
    "display_image(lowres)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-20T21:28:44.269681Z"
    }
   },
   "id": "9ca670b3a422b59d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# SR image\n",
    "SR = bands_to_image(init_test_x+test_out)\n",
    "display_image(SR)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-20T21:28:44.270590Z"
    }
   },
   "id": "9f898ee191cf187b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# high res image\n",
    "highres = bands_to_image(init_test_x+init_test_y)\n",
    "display_image(highres)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-20T21:28:44.271662Z"
    }
   },
   "id": "e7d7d9c479db12e7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# checking PNSR\n",
    "print('PSNR lr: ',tf.image.psnr(lowres[..., tf.newaxis], highres[..., tf.newaxis], max_val=1.0).numpy())\n",
    "print('PSNR sr: ', tf.image.psnr(SR[..., tf.newaxis], highres[..., tf.newaxis], max_val=1.0).numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-20T21:28:44.272590Z"
    }
   },
   "id": "5062f1da151e1c82",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# checking SSIM\n",
    "print('ssim lr:', tf.image.ssim(lowres[..., tf.newaxis], highres[..., tf.newaxis], max_val=1.0).numpy())\n",
    "print('ssim sr:', tf.image.ssim(SR[..., tf.newaxis], highres[..., tf.newaxis], max_val=1.0).numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-20T21:28:44.273879Z"
    }
   },
   "id": "baa24414ea4e755",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-20T21:28:44.274938Z"
    }
   },
   "id": "4d9c093eafb1a025"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
