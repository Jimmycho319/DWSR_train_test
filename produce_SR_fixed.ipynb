{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import image_to_train as tr\n",
    "from model import get_model\n",
    "import test_func as test\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load desired model\n",
    "model = get_model()\n",
    "x2_weight_path = os.path.join('saved_weights', 'Weightx2', 'x2.ckpt')\n",
    "model = test.load_x2_from_weights(model, x2_weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working with bigger datasets can cause memory issues; limit the number of images you generate by indexing the images\n",
    "# else, set the value of try_all_images = True\n",
    "start_idx = 0\n",
    "end_idx = 20\n",
    "try_all_images = False\n",
    "dataset_path = os.path.join('Urban 100', 'X2 Urban100', 'X2', 'LOW X2 Urban')\n",
    "out_path = os.path.join('Urban 100', 'X2 Urban100', 'X2', 'SR X2 Urban')\n",
    "\n",
    "if try_all_images:\n",
    "    image_paths = [os.path.join(dataset_path, f) for f in sorted(os.listdir(dataset_path))]\n",
    "else:\n",
    "    image_paths = [os.path.join(dataset_path, f) for f in sorted(os.listdir(dataset_path))[start_idx:end_idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_decode(path):\n",
    "    im = tf.io.read_file(path)\n",
    "    im = tf.image.decode_image(im, channels=3)\n",
    "    return im\n",
    "rgb_images = [read_and_decode(path) for path in image_paths]\n",
    "images = [tr.preprocess_single_image(im, channel_last=True) for im in rgb_images]\n",
    "plt.imshow(rgb_images[0])\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get SR sub-band residuals\n",
    "predictions = []\n",
    "for image in images:\n",
    "    prediction = model.predict(image, verbose=0)\n",
    "    predictions.append(tf.squeeze(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add residuals to LR image and convert sub-bands to luminance image\n",
    "squeezed_images = [tf.squeeze(im) for im in images]\n",
    "SR_bands = [im + pred for im, pred in zip(squeezed_images, predictions)]\n",
    "SR_lum = []\n",
    "for bands in SR_bands:\n",
    "    SR_lum.append(tr.bands_to_image(bands))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert luminance to rgb\n",
    "SR_rgb_images = [test.luminance_to_rgb(lum, rgb) for lum, rgb in zip(SR_lum, rgb_images)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm images\n",
    "plt.imshow(SR_rgb_images[0])\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store results in out_path directory\n",
    "file_names = ['{:03d}'.format(i) for i in range(start_idx+1, end_idx+1)]\n",
    "test.write_images_to_path(out_path, SR_rgb_images, file_names)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
